{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Anatomie dun réseau de neurones.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olgabernier/Machine-Learning/blob/master/Anatomie_dun_re%CC%81seau_de_neurones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_LGv97uPxX3",
        "colab_type": "text"
      },
      "source": [
        "# Anatomie d'un réseau de neurones\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Les réseaux de neurones sont l'émanation du second des deux grands courants de l'**intelligence artificielle**, qui sont :\n",
        "\n",
        "* L'IA symbolique (basée sur la logique formelle)\n",
        "* L'IA connexionniste (basée sur les équations différentielles)\n",
        "\n",
        "Ces deux voies sont nées très tôt dans l'histoire de l'informatique (si l'on excepte les articles d'Alan Turing). Dès la fin des années 1950, on voit apparaître des tentatives de modélisations de processus dits intelligents.\n",
        "\n",
        "L'**IA symbolique** explore une piste linguistique et logique. En décrivant les règles qui définissent certains systèmes, il sera possible de déduire des conclusions à partir d'observations données, voire de découvrir de nouveaux “théorèmes” (c'est un peu la suite du programme de Hilbert).\n",
        "\n",
        "L'**IA connexionniste** veut au contraire simuler (ou reproduire) les mécanismes de bas niveau de l'intelligence, c'est-à-dire qu'elle prend pour modèle la physiologie et la biologie.\n",
        "\n",
        "Ce sont donc deux approches strictement inversées top-down (symbolique) et bottom-up (connexionnisme).\n",
        "\n",
        "L'IA connexionniste a cherché (globalement) à résoudre trois grandes classes de problèmes :\n",
        "\n",
        "* la **régression**, ou comment trouver une fonction qui approxime une solution d'un ensemble d'équations à *n* variables (e.g. la variation des prix d'un marché en fonction de certains critères)\n",
        "* la **classification** d'échantillons suivant des similarités avec un ensemble de références (e.g. est-ce un chat que je vois sur cette photo ?)\n",
        "* la **prédiction**, ou comment élaborer une réponse nouvelle dans une situation donnée (e.g. jouer aux échecs, traduire un texte)\n",
        "\n",
        "\n",
        "\n",
        "## Qu'est-ce qu'un neurone ?\n",
        "\n",
        "La perspective connexionniste cherche par conséquent à prendre comme modèle le cerveau et ses éléments les plus élémentaires (ou pensés tels) : les **neurones**.\n",
        "\n",
        "Un neurone biologique est constitué grosso modo de trois parties :\n",
        "\n",
        "* Le corps de la cellule\n",
        "* les dendrites, qui permettent l'acheminement de signaux électriques vers le noyau de la cellule\n",
        "* l'axone, qui permet au neurone de renvoyer un signal, s'il est activé.\n",
        "* les neurones sont par ailleurs connectés entre eux par le biais de synapses, où ont lieu des échanges électriques complexes.\n",
        "\n",
        "Le neurone artificiel reprend donc une version simple (voire simpliste) du modèle biologique, en affirmant qu'il constitue une *unité de calcul* comprenant:\n",
        " \n",
        " * un organe sommateur qui reçoit des données...\n",
        " * ... via un certain nombre d'entrées\n",
        " * ... redistribuant les résultats de cette somme via une sortie\n",
        " * ... et qui peut être actif ou inactif en fonction de la valeur qu'il a calculée (effet de seuil)\n",
        " \n",
        " Globalement, un neurone réalise une opération assez simple qui est un **produit scalaire**.\n",
        " \n",
        " **Référence** : [Produit scalaire](https://www.wikiwand.com/fr/Produit_scalaire)\n",
        " \n",
        " ![Neurones biologique et artificiel](http://localhost/images/neurones_2.png)\n",
        " \n",
        " \n",
        "Comme on le voit sur l'image ci-dessus, le neurone reçoit des données d'entrée qu'il **pondère** par des **poids** associés à chaque canal d'entrée.\n",
        " \n",
        "Au neurone est également associée une **fonction d'activation** qui décide si la valeur du résultat du produit scalaire doit être redistribué vers la sortie.\n",
        " \n",
        "On remarque également que l'on peut associer au neurone un **biais**, destiné à assurer la stabilité des calculs.\n",
        "\n",
        "Tel quel, nous avons donc un programme qui, en fonction de données d'entrée et d'un ensemble de valeurs de pondération (poids), produit une valeur (ou zéro).\n",
        "\n",
        "Ça ne paraît pas très utile à première vue. Sauf que, en fait, ce qui nous intéresse ce n'est pas la sortie, mais bien les *conditions de production* de la sortie, c'est-à-dire l'ensemble des poids.\n",
        "\n",
        "Le neurone a donc pour tâche de **trouver une solution** à une équation à *n* inconnues, dont on connaît le résultat.\n",
        "\n",
        "```python\n",
        "y = w1 * x1 + w2 * x2 + w3 * x3\n",
        "```\n",
        "\n",
        "Cette première architecture a été proposée par Frank Rosenblatt en 1957 sous le nom de [perceptron](https://www.wikiwand.com/fr/Perceptron)\n",
        "\n",
        "Le fonctionnement du perceptron, qui reste aujourd'hui la pierre angulaire de l'apprentissage automatique (et/ou profond), consiste à minimiser une *erreur*, c'est-à-dire à trouver le minimum d'une fonction. Pour cela la technique est celle de la **descente du gradient**, très semblable à la méthode de Pascal pour trouver la solution des équations :\n",
        "\n",
        "1. Partir d'une valeur arbitraire *x* et calculer une solution *y(1)*\n",
        "1. Déplacer *x* d'une certaine quantité (appelée ici **pas d'apprentissage**) et calculer une nouvelle solution *y(2)*\n",
        "1. Tant que `y(i+1) - y(i) > 0`, retourner en 2.\n",
        "\n",
        "Dans le vocabulaire de l'apprentissage automatique, une itération de l'algorithme ci-dessus est appelée une **période** (ou “epoch” en anglais).\n",
        "\n",
        "[Tutoriel d'implémentation du perceptron en Python]()\n",
        "\n",
        "En réalité, le perceptron est équivalent à un algorithme de **régression linéaire** et on s'aperçoit assez vite des limitations :\n",
        "\n",
        "1. on ne peut discriminer que des ensembles de points clairement séparés par des droites\n",
        "1. idem pour les solutions de régression\n",
        "\n",
        "Ces limites signent la fin du modèle\n",
        "\n",
        "\n",
        "## Réseaux multi-couches\n",
        "\n",
        "Les limites du perceptron sont dépassées lors de l'apparition des réseaux à couches multiples (ou cachées). On montre en effet qu'un réseau en trois couches (une couche d'entrée, une couche cachée,une couche de sortie) est capable d'approximer des fonctions (continues) arbitrairement complexes.\n",
        "\n",
        "Une **couche** est un ensemble de neurones, tous reliés aux mêmes entrées et aux mêmes sorties. Dans les modèles classiques, les neurones d'une même couche sont *indépendants les uns des autres*. Mais ce n'est pas toujours le cas, comme dans les machines de Boltzmann ou les réseaux de Hopfield. Il peut arriver qu'un neurone rétro-agisse sur lui-même, comme les neurones LSTM, par exemple.\n",
        "\n",
        "La deuxième grande innovation est l'introduction de l'algorithme de **rétropropagation de l'erreur** qui permet d'optimiser grandement la vitesse d'apprentissage. Dans les débits du connexionnisme, les réseaux sont « feedforward », c'est-à-dire que le calcul se fait toujours de la première couche vers la dernière, ce qui fait qu'à chaque échantillon d'apprentissage, on repart avec des poids qui ne tiennent pas compte de l'erreur précédente. On perd donc en précision. La rétropropagation, comme son nom l'indique consiste, une fois un exemple soumis à l'apprentissage, à répercuter l'erreur de la couche de sortie vers la couche d'entrée pour lisser les poids.\n",
        "\n",
        "A la fin des années 199x, apparaissent de nouveaux types de neurones et d'architecture, voire d'algorithmes d'apprentissage.\n",
        "\n",
        "* Les couches à convolution pour l'analyse d'images\n",
        "* Les neurones LSTM pour les problèmes séquentiels (textes, jeux, séries temporelles, etc.)\n",
        "* les couches d'enveloppement (“embedding”)\n",
        "\n",
        "et\n",
        "\n",
        "* l'apprentissage par renforcement\n",
        "* l'apprentissage antagoniste\n",
        "\n",
        "Il est donc probable que les architectures de réseaux se complexifient encore dans le futur.\n",
        "\n",
        "\n",
        "## Composition\n",
        "\n",
        "## Méthodologie\n",
        "\n",
        "La méthodologie générale pour résoudre un problème avec des outils connexionnistes peut être résumée de la manière suivante :\n",
        "\n",
        "### 1. Collecte de données\n",
        "\n",
        "Dans un premier temps, comme dans tout problème, il faut partir d'un **jeu de données** qui répond à un  **modèle** identifié.\n",
        "\n",
        "Dans le cas le plus courant, qui est l'apprentissage supervisé, chaque exemple du jeu de données est **étiqueté**, c'est-à-dire que l'on connaît la réponse associée aux valeurs des différentes dimensions du problème.\n",
        "\n",
        "### 2. Préparation des données\n",
        "\n",
        "Une fois le jeu de données constitué, il est souvent nécessaire de le pré-traiter, ce qui peut prendre plusieurs sens.\n",
        "\n",
        "#### Changement de format\n",
        "\n",
        "Les données peuvent être dans un format inexploitable pour le réseau de neurones. L'exemple le plus simple est celui du jeu de données MNIST pour la reconnaissance de caractères manuscrits. Les exemples sont dans une seule grande image et les étiquettes dans un fichier binaire. Il existe par ailleurs des jeux de données *compatibles* avec MNIST mais dont les données sont représentées sous d'autres formats.\n",
        "\n",
        "Cette première manipulation concerne donc plutôt le décodage des données.\n",
        "\n",
        "#### Changement de représentation\n",
        "\n",
        "Dans de nombreux problèmes, on est confronté à des données textuelles, comme lorsque vous voulez prédire le prix d'un appartement en fonction de la ville. Les noms de ville ne peuvent pas être exploités directement ; il est indispensable de les transformer en valeurs numériques. La règle générale est d'utiliser pour cela une représentation appelée “**one hot**” qui correspond à une [matrice identité](https://www.wikiwand.com/fr/Matrice_identit%C3%A9).\n",
        "\n",
        "#### Réduction de dimensionnalité\n",
        "\n",
        "Le plus gros problème des réseaux de neurones, souvent appelé « *malédiction de la dimensionnalité* » se situe dans l'explosion combinatoire de l'exploration des solutions. Typiquement, chaque neurone est connecté à tous les neurones de la couche précédente et de la couche suivante. Chaque connexion est une dimension du problème à résoudre. Par conséquent, on se retrouve très rapidement à devoir gérer des systèmes à plusieurs centaines de milliers voire des millions d'inconnues (paramètres).\n",
        "\n",
        "On essaiera donc de minimiser les caractéristiques. Une bonne solution peut être l'utilisation de l'**analyse en composantes principales** pour estimer le degré de corrélation entre les caractéristiques.\n",
        "\n",
        "#### Nettoyage des données\n",
        "\n",
        "Comme dans tous les cas que nous avons rencontrés auparavant, la clef du succès est la qualité du jeu de données initial. On se ramènera donc aux techniques vues précédemment pour vérifier celle-ci.\n",
        "\n",
        "#### Mise en forme des données\n",
        "\n",
        "La dernière étape du processus de préparation des données consiste à créer les *tenseurs* qui serviront à alimenter le réseau de neurones.\n",
        "\n",
        "### 3. Construction du modèle\n",
        "\n",
        "L'autre composante essentielle du système est l'architecture du réseau de neurones. Celle-ci peut se considérer à plusieurs niveaux.\n",
        "\n",
        "1. L'architecture globale, qui est souvent liée à un type d'algorithmique particulier. En dehors des réseaux classiques, il existe toute une variété d'approches comme les réseaux de Hopfield, des machines de Boltzmann, les cartes de Kohonen, etc. qui sont des formes particulières de systèmes connexionnistes (fondés sur des « *neurones artificiels* ».\n",
        "1. L'architecture fine, qui concernera l'ordonnancement des neurones en couches et des couches en structure de transfert entre lest entrées et les sorties. Là aussi, en fonction des types de problèmes, on voit apparaître des éléments différents (neurones LSTM, à convolution, etc.)\n",
        "1. L'architectures stratégique, qui consistera à choisir un système de résolution en fonction de ce que l'on veut trouver. On parlera à ce moment d'apprentissage par renforcement, antagoniste, supervisé, non supervisé, etc.\n",
        "1. L'urbanisme connexionniste, dans lequel on considérera le réseau de neurones comme *une partie* d'une architecture plus vaste pour la résolution de problèmes.\n",
        "\n",
        "\n",
        "### 4. Entraînement du modèle\n",
        "\n",
        "Une fois le modèle construit, on lui soumet un jeu d'apprentissage pour lequel chaque *exemple* a été *étiqueté* (dans la grande majorité des cas, hormis les cas d'apprentissage non supervisé). Globalement, on pose une question à la machine et on lui donne la réponse. On essaie donc de construire une mémoire associative entre une entrée et une sortie.\n",
        "\n",
        "LA principale difficulté de cette phase est le réglage des **hyperparamètres** du réseau. On cherche à obtenir la réponse optimale, mais c'est un peu comme chercher ses clefs là où il n'y a pas de lampadaire. Ces hypermaramètres peuvent être nombreux :\n",
        "\n",
        "* nombre de couches\n",
        "* nombre de neurones par couche\n",
        "* nombre d'itérations (*epochs*)\n",
        "* pas d'apprentissage\n",
        "* taille des lots\n",
        "* etc.\n",
        "\n",
        "On sera souvent obligé, dans les cas réels, de procéder par essais et erreurs jusqu'à parvenir à la meilleure solution.\n",
        "\n",
        "\n",
        "### 5. Utilisation\n",
        "\n",
        "Une fois le modèle entraîné, il devient autonome. On peut le sauvegarder dans un fichier externe et le rappeler pour soumettre de nouveaux cas.\n",
        "\n",
        "Si le réseau a appris correctement, il pourra donner des réponses justes même dans des situations qu'il n'a jamais rencontrées auparavant.\n",
        "\n",
        "* Dans le cas de la régression, on aura approximé une “courbe“ suffisamment précise et donc le point sera proche de la valeur correcte ;\n",
        "* Dans le cas de la classification, le modèle aura trouvé des frontières suffisamment bonnes pour que chaque cas soit associé au bon ensemble.\n",
        "\n",
        "\n",
        "## Glossaire\n",
        "\n",
        "Vous pouvez sur le site de Google un glossaire très complet :\n",
        "\n",
        "**Source** : [Glossaire de l'apprentissage automatique](https://developers.google.com/machine-learning/glossary/)\n",
        "\n",
        "Les principaux termes sont :\n",
        "\n",
        "### Fonction d'activation\n",
        "\n",
        "> Fonction (par exemple ReLU ou sigmoïde) qui utilise la somme pondérée de toutes les entrées de la couche précédente pour générer une valeur de sortie (généralement non linéaire) et la transmettre à la couche suivante.\n",
        "\n",
        "### Lot\n",
        "\n",
        "> Ensemble d'exemples utilisés dans une itération (c'est-à-dire, une mise à jour du gradient) de l'entraînement du modèle.\n",
        "\n",
        "### Biais\n",
        "\n",
        "> Ordonnée à l'origine ou décalage par rapport à une origine. Le biais est noté b ou w0 dans les modèles de machine learning. Par exemple, b représente le biais dans la formule suivante\n",
        "\n",
        "### Caractéristique catégorielle\n",
        "\n",
        "> Caractéristiques avec un ensemble discret de valeurs possibles. Par exemple, une caractéristique catégorique nommée house style, avec l'ensemble discret de trois valeurs possibles suivant : Tudor, ranch, colonial. En représentant house style comme une donnée catégorielle, le modèle peut apprendre l'impact de chaque valeur Tudor, ranch et colonial sur la valeur immobilière.\n",
        "\n",
        "> Parfois, les valeurs de l'ensemble discret s'excluent mutuellement, et une seule valeur peut être appliquée à un exemple donné. Par exemple, la caractéristique catégorique car maker n'autoriserait probablement qu'une seule valeur (Toyota) pour chaque exemple. Dans d'autres cas, plusieurs valeurs peuvent s'appliquer. Une voiture peut être peinte de différentes couleurs. Ainsi, la caractéristique catégorique car color autoriserait probablement plusieurs valeurs (par exemple, red et white) pour un exemple.\n",
        "\n",
        "### Classe\n",
        "\n",
        "> Un des ensembles de valeurs cibles énumérées pour une étiquette. Par exemple, dans un modèle de classification binaire de détection du spam, les deux classes sont spam et non-spam. Dans un modèle de classification à classes multiples qui identifie les races de chiens, les classes peuvent être caniche, beagle, carlin, etc.\n",
        "\n",
        "### Matrice de confusion\n",
        "\n",
        "> Table NxN qui résume la réussite des prédictions d'un modèle de classification, c'est-à-dire la corrélation entre les étiquettes et les classifications du modèle. L'un des axes d'une matrice de confusion est l'étiquette prédite par le modèle, et l'autre l'étiquette réelle. N correspond au nombre de classes. \n",
        "\n",
        "### Caractéristique continue\n",
        "\n",
        "> Caractéristique à virgule flottante avec une plage infinie de valeurs possibles.\n",
        "\n",
        "### Convergence\n",
        "\n",
        "> Désigne familièrement un état atteint pendant l'apprentissage, dans lequel la perte d'apprentissage et la perte de validation varient peu ou pas du tout entre chaque itération, passé un certain nombre d'itérations. Autrement dit, un modèle atteint la convergence lorsque la poursuite de l'apprentissage sur les données actuelles n'améliore pas le modèle. Dans le deep learning, les valeurs de perte restent parfois constantes ou presque pendant de nombreuses itérations avant de finalement diminuer, faisant croire à tort, temporairement, que la convergence a été atteinte.\n",
        "\n",
        "### Itération (epoch)\n",
        "\n",
        "> Cycle d'apprentissage complet sur l'intégralité de l'ensemble de données de manière à ce que chaque exemple ait été vu une fois. Une itération représente ainsi N/taille du lot itérations d'apprentissage, où N est le nombre total d'exemples.\n",
        "\n",
        "### Exemple \n",
        "\n",
        "> Ligne d'un ensemble de données. Un exemple contient une ou plusieurs caractéristiques, et éventuellement une étiquette. Voir aussi Exemple étiqueté et Exemple sans étiquette.\n",
        "\n",
        "### Caractéristique (feature)\n",
        "\n",
        "> Variable d'entrée utilisée pour effectuer des prédictions.\n",
        "\n",
        "### Descente de gradient\n",
        "\n",
        "> Technique de minimisation de la perte en calculant les gradients de la perte pour les paramètres du modèle, en fonction des données d'apprentissage. La descente de gradient ajuste de manière itérative les paramètres afin de trouver progressivement la meilleure combinaison de pondérations et de biais pour minimiser la perte.\n",
        "\n",
        "### Couche cachée\n",
        "\n",
        "> Couche synthétique d'un réseau de neurones entre la couche d'entrée (c'est-à-dire, les caractéristiques) et la couche de sortie (la prédiction). Un réseau de neurones se compose d'une ou plusieurs couches cachées.\n",
        "\n",
        "### Etiquette\n",
        "\n",
        "> Dans l'apprentissage supervisé, \"réponse\" ou \"résultat\" d'un exemple. Chaque exemple d'un ensemble de données étiqueté se compose d'au moins une caractéristique et d'une étiquette. Par exemple, les caractéristiques d'un ensemble de données sur des logements pourraient inclure le nombre de chambres, le nombre de salles de bain et l'âge du logement, et l'étiquette pourrait être le prix du logement. Dans un ensemble de données de détection de spam, les caractéristiques pourraient être l'objet, l'expéditeur et le message lui-même, et l'étiquette serait probablement \"spam\" ou \"non spam.\"\n",
        "\n",
        "### Taux (ou pas) d'apprentissage\n",
        "\n",
        "> Grandeur scalaire utilisée pour entraîner le modèle via la descente de gradient. À chaque itération, l'algorithme de descente de gradient multiplie le taux d'apprentissage par le gradient. Le produit ainsi généré est appelé pas de gradient. Le taux d'apprentissage est un hyperparamètre clé.\n",
        "\n",
        "### Hyperparamètre\n",
        "\n",
        "> Les paramètres que vous réglez pendant les exécutions successives de l'entraînement du modèle. Le taux d'apprentissage, par exemple, est un hyperparamètre.\n",
        "\n",
        "### Paramètre\n",
        "\n",
        "> Variable d'un modèle que le système de machine learning entraîne tout seul. Par exemple, les pondérations sont des paramètres dont le système de machine learning apprend progressivement les valeurs via des itérations d'apprentissage successives.\n",
        "\n",
        "### Encodage one-hot\n",
        "> Vecteur creux caractérisé ainsi :\n",
        "> * Un élément a la valeur 1.\n",
        "> * Tous les autres éléments ont la valeur 0.\n",
        ">\n",
        "> L'encodage one-hot est couramment utilisé pour représenter des chaînes ou des identifiants qui ont un ensemble fini de valeurs possibles. Supposons qu'un ensemble de données botaniques donné répertorie 15 000 espèces différentes, chacune associée à un identifiant unique. Dans le cadre de l'extraction de caractéristiques, vous encoderez probablement ces identifiants sous forme de vecteurs one-hot, dont la taille est de 15 000.\n",
        "\n",
        "### Modèle de régression\n",
        "\n",
        "> Type de modèle qui génère des valeurs continues (à virgule flottante, généralement). À comparer aux modèles de classification, qui génèrent des valeurs discrètes, comme \"hémérocalle\" ou \"lis tigré\".\n",
        "\n",
        "### Modèle de séquence\n",
        "\n",
        "> Modèle dont les entrées présentent une dépendance séquentielle. Par exemple, prévision de la prochaine vidéo visionnée à partir d'une séquence de vidéos précédemment regardées.\n",
        "\n",
        "### Modèle de classification\n",
        "\n",
        "> Type de modèle de machine learning permettant de différencier deux classes discrètes ou plus. Par exemple, un modèle de classification par traitement du langage naturel pourrait déterminer si une phrase en entrée est en français, en espagnol ou en italien. À comparer au modèle de régression.\n",
        "\n",
        "\n",
        "\n",
        "## Pour aller plus loin\n",
        "\n",
        "Nous présentons ici les bases des réseaux de neurones, mais ces derniers sont loin d'être les seuls outils de résolution de problèmes complexes.\n",
        "\n",
        "Beaucoup d'algorithmes connus peuvent être utilisés pour trouver des solutions, comme :\n",
        "\n",
        "* k plus proches voisins\n",
        "* random forests\n",
        "\n",
        "Sans compter  :\n",
        "\n",
        "* programmation logique\n",
        "* programmation par contraintes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7ue5iJ4PxX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}